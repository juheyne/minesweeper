\documentclass[Optionen]{scrartcl} 

\title{Playing Minesweeper with Deep Reinforcement Learning}
\author{Bayirli, Merve \and Ebadi, Payam \and Heyne, Julian}

\begin{document}
    \maketitle
    \section{Motivation}
    Reinforcement Learning is an interesting field of machine learning.
    It is connected to learning in humans and animals.
    An agent learns which actions to take in an environment given certain rewards.
    However, the naive algorithms struggle with high--dimensional sensory input.
    One way to bypass this problem is the usage of hand--crafted features.
    These systems are unfortunately not easily applicable to other problems and highly depend on the quality of the feature representation.
    With the success of deep learning in the past few years, it stands to reason that those achievements can be used in Reinforcement Learning.
    Google Deepmind played seven, and later 49 Atari games with a deep Q--network.
    Alpha Go Zero sparked new interest in Reinforcement Learning.
    
    Minesweeper is a game almost everyone, who used Microsoft Windows, knows.
    This makes it an interesting subject for project.
    Playing it with a deep reinforcement learning approach enables us learn more in the field of deep reinforcement learning.
    \section{Methods}
    We want to use a deep Q--network, also used by Google Deepmind to play the Atari games.
    The input will be a numerical representation of the minesweeper game board.
    We won't use the image of a specific minesweeper game, but instead use matrix containing the board information.
    
    For learning the deep Q--network an experience replay mechanism will be used.
    \section{Experiments}
    We want to experiment with different level of difficulties of minesweeper games.
    The original Minesweeper versions has three different level of difficulties: Beginner, Intermediate, and Expert with 10, 40 and 99 mines respectively.
    Reinforcement Learning especially with a deep network to encode the input has a lot of parameters.
    The size and number of convolutional layers for example.
    We want to experiment and try out different combinations of parameters to see how it influences the learning as well as the accuracy of the resulting agent.
\end{document}