\documentclass[Optionen]{scrartcl}

%\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

\usepackage[
backend=biber,
style=numeric,
sortlocale=en_US,
natbib=true,
url=false, 
doi=true,
eprint=false
]{biblatex}
\addbibresource{proposal.bib}


\title{Playing Minesweeper with Deep Reinforcement Learning}
\author{Bayirli, Merve \and Ebadi, Payam \and Heyne, Julian}

\begin{document}
    \maketitle
    \section{Motivation}
    Reinforcement Learning is an interesting field of machine learning.
    An agent learns which actions to take in an environment given certain rewards.
    However, the naive algorithms struggle with high--dimensional sensory input.
    One way to bypass this problem is the usage of hand--crafted features.
    These systems are unfortunately not easily applicable to other problems and highly depend on the quality of the feature representation.
    Deep learning makes it possible to extract higher levels of abstractions from raw sensory input.
    These techniques are for example used by Google Deepmind to play seven, and later 49 Atari games with a deep Q--network~\cite{mnih2013playing, mnih2015human}.
    
    Minesweeper is a game almost everyone, who used Microsoft Windows, knows.
    This makes it an interesting subject for a project applying reinforcement learning.
    Playing it with a deep reinforcement learning approach enables us learn more in the fields of reinforcement as well as deep learning.
    \section{Methods}
    We want to use a deep Q--network, also used by Google Deepmind to play the Atari games.
    The input will be a numerical representation of the minesweeper game board.
    We won't use the image of a specific minesweeper game, but instead use matrix containing the board information.
    The Minesweeper game is self--implemented in Python and we will use Tensorflow for the Deep Q--network.

    \section{Experiments}
    We want to experiment with different level of difficulties of minesweeper games.
    The original Minesweeper versions has three different level of difficulties: Beginner, Intermediate, and Expert with 10, 40 and 99 mines respectively.
    Reinforcement Learning especially with a deep network to encode the input has a lot of parameters.
    The size and number of convolutional layers for example.
    Thus, we want to experiment and try out different combinations of parameters to see how it influences the learning as well as the accuracy of the resulting agent.
    Additionally we want to compare our results with those of other approaches, e.g.~\cite{castillo2003learning}.
    
    \printbibliography
\end{document}